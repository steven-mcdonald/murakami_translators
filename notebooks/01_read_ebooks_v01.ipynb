{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ebooks to text files ###\n",
    "* select books based on format suffix\n",
    "* epub read using ebooklib and BeautifulSoup\n",
    "* docx read with ...\n",
    "* pdf read with ...\n",
    "* save each text format book as pickle archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T16:10:21.443870Z",
     "start_time": "2020-05-28T16:10:21.437310Z"
    }
   },
   "outputs": [],
   "source": [
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import os\n",
    "import docx\n",
    "import textract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in epub format files\n",
    "Selecting only epub format files from the ebook folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:24:17.067554Z",
     "start_time": "2020-05-28T15:24:17.061613Z"
    }
   },
   "outputs": [],
   "source": [
    "blacklist = ['[document]','noscript','header','html','meta','head','input','script']\n",
    "# there may be more elements you don't want, such as \"style\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:24:18.357546Z",
     "start_time": "2020-05-28T15:24:18.350740Z"
    }
   },
   "outputs": [],
   "source": [
    "def epub2thtml(epub_path):\n",
    "    book = epub.read_epub(epub_path)\n",
    "    chapters = []\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            chapters.append(item.get_content())\n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:24:21.425279Z",
     "start_time": "2020-05-28T15:24:21.419000Z"
    }
   },
   "outputs": [],
   "source": [
    "def chap2text(chap):\n",
    "    output = ''\n",
    "    soup = BeautifulSoup(chap, 'html.parser')\n",
    "    text = soup.find_all(text=True)\n",
    "    for t in text:\n",
    "        if t.parent.name not in blacklist:\n",
    "            output += '{} '.format(t)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:24:21.789142Z",
     "start_time": "2020-05-28T15:24:21.782192Z"
    }
   },
   "outputs": [],
   "source": [
    "def thtml2ttext(thtml):\n",
    "    Output = []\n",
    "    for html in thtml:\n",
    "        text =  chap2text(html)\n",
    "        Output.append(text)\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:24:22.236735Z",
     "start_time": "2020-05-28T15:24:22.230418Z"
    }
   },
   "outputs": [],
   "source": [
    "def epub2text(epub_path):\n",
    "    chapters = epub2thtml(epub_path)\n",
    "    ttext = thtml2ttext(chapters)\n",
    "    return ttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:39:56.773190Z",
     "start_time": "2020-05-28T15:39:56.763448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HarukiMurakami_ColorlessTsukuruTazaki',\n",
       " 'HarukiMurakami_TheWindUpBirdChronicle',\n",
       " 'HarukiMurakami_AWildSheepChase',\n",
       " 'HarukiMurakami_NorwegianWood',\n",
       " 'HarukiMurakami_KafkaOnTheShore',\n",
       " 'HarukiMurakami_DanceDanceDance']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_dir = '../../../../Documents/murakami/ebooks/'\n",
    "epub_list = os.listdir(book_dir)\n",
    "epub_list = [x.split('.')[0] for x in epub_list if x.split('.')[1] == 'epub']\n",
    "epub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:40:15.457604Z",
     "start_time": "2020-05-28T15:40:09.901979Z"
    }
   },
   "outputs": [],
   "source": [
    "out_dir = '../../../../Documents/murakami/pkl_raw_books/'\n",
    "for book in epub_list:\n",
    "    epub_full_path = book_dir + book + '.epub'\n",
    "    out_full_path = out_dir + book + '.pkl'\n",
    "    output=epub2text(epub_full_path)\n",
    "    with open(out_full_path, 'wb') as fp:\n",
    "        pickle.dump(output, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in docx format files\n",
    "Selecting only docx format files from the ebook folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:56:48.245435Z",
     "start_time": "2020-05-28T15:56:48.233217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HarukiMurakami_TheElephantVanishes']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_list = os.listdir(book_dir)\n",
    "docx_list = [x.split('.')[0] for x in docx_list if x.split('.')[1] == 'docx']\n",
    "docx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:58:58.966780Z",
     "start_time": "2020-05-28T15:58:58.960405Z"
    }
   },
   "outputs": [],
   "source": [
    "def getText(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:59:55.607880Z",
     "start_time": "2020-05-28T15:59:55.489638Z"
    }
   },
   "outputs": [],
   "source": [
    "for book in docx_list:\n",
    "    docx_full_path = book_dir + book + '.docx'\n",
    "    out_full_path = out_dir + book + '.pkl'\n",
    "    output = getText(docx_full_path)\n",
    "    with open(out_full_path, 'wb') as fp:\n",
    "        pickle.dump(output, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T16:08:06.340743Z",
     "start_time": "2020-05-28T16:08:06.333143Z"
    }
   },
   "source": [
    "### Read in pdf format files\n",
    "Selecting only pdf format files from the ebook folder.\n",
    "They all relate to a single book in this case so group together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T16:11:22.608218Z",
     "start_time": "2020-05-28T16:11:22.595578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nw_b_split_004-021_1page',\n",
       " 'nw_b_split_022-049_1page',\n",
       " 'nw_b_split_050-066_1page',\n",
       " 'nw_b_split_067-080_1page',\n",
       " 'nw_b_split_081-109_1page',\n",
       " 'nw_b_split_110-129_1page']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_list = os.listdir(book_dir)\n",
    "pdf_list = [x.split('.')[0] for x in pdf_list if x.split('.')[1] == 'pdf']\n",
    "pdf_list.sort()\n",
    "pdf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T16:14:33.734116Z",
     "start_time": "2020-05-28T16:14:05.077182Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in each pdf chunk and form into string\n",
    "texts = str()\n",
    "for pdf_ in pdf_list:\n",
    "    pdf_full_path = book_dir + pdf_ + '.pdf'\n",
    "#     need decode(\"utf-8\") to convert to string\n",
    "#     need split to split into pages and then select alternate pages as each one is read twice\n",
    "    text = textract.process(pdf_full_path, language='eng', method='pdfminer').decode(\"utf-8\").split('\\x0c')[::2]\n",
    "    text_sel = str()\n",
    "    for t in text:\n",
    "        text_sel += t\n",
    "    texts += text_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T16:17:58.098538Z",
     "start_time": "2020-05-28T16:17:58.090980Z"
    }
   },
   "outputs": [],
   "source": [
    "out_full_path = out_dir + 'HarukiMurakami_NorwegianWood_b' + '.pkl'\n",
    "with open(out_full_path, 'wb') as fp:\n",
    "    pickle.dump(texts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
